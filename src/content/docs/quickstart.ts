import type { DocPage, CodeExample } from './types';

// =============================================================================
// Quick Start Page Content
// =============================================================================

export const quickstartPage: DocPage = {
  slug: 'quickstart',
  title: {
    en: 'Quick Start',
    zh: 'å¿«é€Ÿå¼€å§‹',
  },
  description: {
    en: 'Get started with Omni Memory in 5 minutes. Learn how to save and search memories with just a few lines of code.',
    zh: '5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹ Omni Memoryã€‚åªéœ€å‡ è¡Œä»£ç å³å¯ä¿å­˜å’Œæœç´¢è®°å¿†ã€‚',
  },
  sections: [
    {
      id: 'installation',
      heading: {
        en: 'Installation',
        zh: 'å®‰è£…',
      },
      content: {
        en: 'Install the Python SDK using pip:',
        zh: 'ä½¿ç”¨ pip å®‰è£… Python SDKï¼š',
      },
      codeExamples: [
        {
          language: 'bash',
          code: 'pip install omem',
        },
      ],
    },
    {
      id: 'setup',
      heading: {
        en: 'Set Up Your Account (One-Time)',
        zh: 'è®¾ç½®è´¦æˆ·ï¼ˆä¸€æ¬¡æ€§ï¼‰',
      },
      content: {
        en: `Before using the SDK, complete these one-time setup steps:

1. **Sign up** at [omnimemory.ai](https://omnimemory.ai)
2. **Create an API Key** â€” Dashboard â†’ API Keys â†’ Create New (starts with \`qbk_\`)
3. **Configure LLM** â€” Dashboard â†’ Memory Policy â†’ Add your LLM key (e.g., OpenAI \`sk-...\`)

âš ï¸ **LLM configuration is required!** Without it, you'll get a "Missing required data" error.

ğŸ‘‰ **[Detailed Setup Guide](/docs/guides/setup)** â€” Step-by-step instructions with troubleshooting`,
        zh: `ä½¿ç”¨ SDK ä¹‹å‰ï¼Œè¯·å®Œæˆä»¥ä¸‹ä¸€æ¬¡æ€§è®¾ç½®æ­¥éª¤ï¼š

1. **æ³¨å†Œ** [omnimemory.ai](https://omnimemory.ai)
2. **åˆ›å»º API å¯†é’¥** â€” æ§åˆ¶å° â†’ API å¯†é’¥ â†’ åˆ›å»ºæ–°å¯†é’¥ï¼ˆä»¥ \`qbk_\` å¼€å¤´ï¼‰
3. **é…ç½® LLM** â€” æ§åˆ¶å° â†’ è®°å¿†ç­–ç•¥ â†’ æ·»åŠ æ‚¨çš„ LLM å¯†é’¥ï¼ˆå¦‚ OpenAI \`sk-...\`ï¼‰

âš ï¸ **LLM é…ç½®æ˜¯å¿…éœ€çš„ï¼** æ²¡æœ‰å®ƒï¼Œæ‚¨ä¼šæ”¶åˆ°"ç¼ºå°‘å¿…éœ€æ•°æ®"é”™è¯¯ã€‚

ğŸ‘‰ **[è¯¦ç»†è®¾ç½®æŒ‡å—](/docs/guides/setup)** â€” åŒ…å«æ•…éšœæ’é™¤çš„åˆ†æ­¥è¯´æ˜`,
      },
    },
    {
      id: 'basic-usage',
      heading: {
        en: 'Basic Usage (30 seconds)',
        zh: 'åŸºæœ¬ç”¨æ³•ï¼ˆ30 ç§’ä¸Šæ‰‹ï¼‰',
      },
      content: {
        en: `Three lines of code is all you need:

1. **Initialize** - Create a Memory instance with your API key
2. **Save** - Add conversations to memory
3. **Search** - Query your memories`,
        zh: `åªéœ€ä¸‰è¡Œä»£ç ï¼š

1. **åˆå§‹åŒ–** - ä½¿ç”¨ API å¯†é’¥åˆ›å»º Memory å®ä¾‹
2. **ä¿å­˜** - å°†å¯¹è¯æ·»åŠ åˆ°è®°å¿†ä¸­
3. **æœç´¢** - æŸ¥è¯¢è®°å¿†`,
      },
      codeExamples: [
        {
          language: 'python',
          title: 'Python',
          code: `from omem import Memory

mem = Memory(api_key="qbk_xxx")  # That's it!

# Save a conversation
mem.add("conv-001", [
    {"role": "user", "content": "Meeting with Caroline tomorrow at West Lake"},
    {"role": "assistant", "content": "Got it, I'll remember that"},
])

# Search memories
result = mem.search("When am I going to West Lake?")
if result:
    print(result.to_prompt())  # Formatted for LLM context`,
        },
      ],
    },
    {
      id: 'whats-happening',
      heading: {
        en: "What's Happening Behind the Scenes",
        zh: 'åå°å‘ç”Ÿäº†ä»€ä¹ˆ',
      },
      content: {
        en: `When you call \`add()\`:
- Your conversation is sent to the Omni Memory cloud
- We extract entities, events, and semantic information
- Memories become searchable within 5-30 seconds

When you call \`search()\`:
- We find relevant memories using hybrid vector + knowledge graph search
- Results are ranked by relevance and recency
- You get structured evidence to inject into your LLM context`,
        zh: `å½“ä½ è°ƒç”¨ \`add()\` æ—¶ï¼š
- å¯¹è¯è¢«å‘é€åˆ° Omni Memory äº‘ç«¯
- æˆ‘ä»¬æå–å®ä½“ã€äº‹ä»¶å’Œè¯­ä¹‰ä¿¡æ¯
- è®°å¿†åœ¨ 5-30 ç§’å†…å˜å¾—å¯æœç´¢

å½“ä½ è°ƒç”¨ \`search()\` æ—¶ï¼š
- æˆ‘ä»¬ä½¿ç”¨æ··åˆå‘é‡ + çŸ¥è¯†å›¾è°±æœç´¢æ‰¾åˆ°ç›¸å…³è®°å¿†
- ç»“æœæŒ‰ç›¸å…³æ€§å’Œæ—¶é—´æ’åº
- ä½ è·å¾—ç»“æ„åŒ–çš„è¯æ®æ³¨å…¥åˆ° LLM ä¸Šä¸‹æ–‡ä¸­`,
      },
    },
    {
      id: 'agent-integration',
      heading: {
        en: 'Integrate with Your Agent',
        zh: 'é›†æˆåˆ°ä½ çš„ Agent',
      },
      content: {
        en: 'Here\'s a minimal pattern for adding memory to any LLM-based agent:',
        zh: 'ä»¥ä¸‹æ˜¯å°†è®°å¿†æ·»åŠ åˆ°ä»»ä½•åŸºäº LLM çš„ Agent çš„æœ€ç®€æ¨¡å¼ï¼š',
      },
      codeExamples: [
        {
          language: 'python',
          title: 'Agent Integration Pattern',
          code: `from omem import Memory

class MyAgent:
    def __init__(self, api_key: str, user_id: str = None):
        self.mem = Memory(api_key=api_key, user_id=user_id)
        self.messages = []
    
    def chat(self, user_input: str) -> str:
        # 1. Record user message
        self.messages.append({"role": "user", "content": user_input})
        
        # 2. Search relevant memories
        memory_context = ""
        result = self.mem.search(user_input, fail_silent=True)
        if result:
            memory_context = f"\\n\\n[Relevant Memories]\\n{result.to_prompt()}"
        
        # 3. Call LLM with memory context
        response = your_llm.chat(
            system=f"You are a helpful assistant.{memory_context}",
            messages=self.messages,
        )
        
        # 4. Record assistant response
        self.messages.append({"role": "assistant", "content": response})
        return response
    
    def end_conversation(self):
        # 5. Save conversation to memory when done
        if self.messages:
            self.mem.add(f"conv-{uuid4()}", self.messages)
            self.messages = []`,
        },
      ],
    },
    {
      id: 'next-steps',
      heading: {
        en: 'Next Steps',
        zh: 'ä¸‹ä¸€æ­¥',
      },
      content: {
        en: `- [Account Setup Guide](/docs/guides/setup) - API keys & LLM configuration (BYOK)
- [SDK Reference](/docs/sdk/python) - Full API documentation
- [Agent Integration](/docs/guides/agent) - Add memory to your LLM agent
- [Error Handling](/docs/reference/errors) - Graceful degradation`,
        zh: `- [è´¦æˆ·è®¾ç½®æŒ‡å—](/docs/guides/setup) - API å¯†é’¥å’Œ LLM é…ç½® (BYOK)
- [SDK å‚è€ƒ](/docs/sdk/python) - å®Œæ•´ API æ–‡æ¡£
- [Agent é›†æˆ](/docs/guides/agent) - ä¸º LLM Agent æ·»åŠ è®°å¿†
- [é”™è¯¯å¤„ç†](/docs/reference/errors) - ä¼˜é›…é™çº§`,
      },
    },
  ],
};


