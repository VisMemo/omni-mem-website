import type { DocPage } from '../types';

// =============================================================================
// Setup Guide - API Keys & BYOK LLM Configuration
// =============================================================================

export const setupGuidePage: DocPage = {
  slug: 'guides/setup',
  title: {
    en: 'Account Setup',
    zh: 'è´¦æˆ·è®¾ç½®',
  },
  description: {
    en: 'Complete guide to setting up your Omni Memory account: create API keys and configure your LLM provider.',
    zh: 'å®Œæ•´çš„ Omni Memory è´¦æˆ·è®¾ç½®æŒ‡å—ï¼šåˆ›å»º API å¯†é’¥å¹¶é…ç½® LLM æä¾›å•†ã€‚',
  },
  sections: [
    {
      id: 'overview',
      heading: {
        en: 'Overview',
        zh: 'æ¦‚è¿°',
      },
      content: {
        en: `Before using Omni Memory, you need to complete two setup steps:

1. **Create an API Key** â€” Authenticates your SDK/API calls
2. **Configure an LLM Provider (BYOK)** â€” Powers entity extraction and knowledge processing

Both steps take about 2 minutes total.`,
        zh: `åœ¨ä½¿ç”¨ Omni Memory ä¹‹å‰ï¼Œæ‚¨éœ€è¦å®Œæˆä¸¤ä¸ªè®¾ç½®æ­¥éª¤ï¼š

1. **åˆ›å»º API å¯†é’¥** â€” ç”¨äº SDK/API è°ƒç”¨çš„èº«ä»½éªŒè¯
2. **é…ç½® LLM æä¾›å•† (BYOK)** â€” é©±åŠ¨å®ä½“æå–å’ŒçŸ¥è¯†å¤„ç†

ä¸¤ä¸ªæ­¥éª¤æ€»å…±å¤§çº¦éœ€è¦ 2 åˆ†é’Ÿã€‚`,
      },
    },
    {
      id: 'create-account',
      heading: {
        en: 'Step 1: Create Your Account',
        zh: 'ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºè´¦æˆ·',
      },
      content: {
        en: `1. Go to [omnimemory.ai](https://omnimemory.ai) and click **Sign Up**
2. Enter your email and create a password
3. Verify your email address
4. You'll be redirected to the Dashboard`,
        zh: `1. è®¿é—® [omnimemory.ai](https://omnimemory.ai) å¹¶ç‚¹å‡»**æ³¨å†Œ**
2. è¾“å…¥æ‚¨çš„é‚®ç®±å¹¶åˆ›å»ºå¯†ç 
3. éªŒè¯æ‚¨çš„é‚®ç®±åœ°å€
4. æ‚¨å°†è¢«é‡å®šå‘åˆ°æ§åˆ¶å°`,
      },
    },
    {
      id: 'create-api-key',
      heading: {
        en: 'Step 2: Create an API Key',
        zh: 'ç¬¬äºŒæ­¥ï¼šåˆ›å»º API å¯†é’¥',
      },
      content: {
        en: `Your API key authenticates all SDK and API requests. Each key starts with \`qbk_\`.

### How to Create

1. Go to **Dashboard â†’ API Keys** (or click "API å¯†é’¥" in the sidebar)
2. Click **Create New Key** (åˆ›å»ºæ–°å¯†é’¥)
3. Enter a descriptive label (e.g., "Production", "Development", "My Agent")
4. Click **Create**
5. **Copy the key immediately** â€” it won't be shown again!

### Best Practices

- **Use separate keys for dev/prod** â€” Easier debugging and usage tracking
- **Never commit keys to git** â€” Use environment variables instead
- **Rotate keys periodically** â€” Security hygiene
- **Label keys descriptively** â€” Know which app uses which key

### Example Usage

\`\`\`python
import os
from omem import Memory

# Load from environment variable (recommended)
mem = Memory(api_key=os.environ["OMEM_API_KEY"])

# Or directly (for testing only)
mem = Memory(api_key="qbk_your_key_here")
\`\`\``,
        zh: `API å¯†é’¥ç”¨äºéªŒè¯æ‰€æœ‰ SDK å’Œ API è¯·æ±‚ã€‚æ¯ä¸ªå¯†é’¥ä»¥ \`qbk_\` å¼€å¤´ã€‚

### å¦‚ä½•åˆ›å»º

1. è¿›å…¥**æ§åˆ¶å° â†’ API å¯†é’¥**ï¼ˆæˆ–ç‚¹å‡»ä¾§è¾¹æ çš„"API å¯†é’¥"ï¼‰
2. ç‚¹å‡»**åˆ›å»ºæ–°å¯†é’¥**
3. è¾“å…¥æè¿°æ€§æ ‡ç­¾ï¼ˆå¦‚"ç”Ÿäº§ç¯å¢ƒ"ã€"å¼€å‘ç¯å¢ƒ"ã€"æˆ‘çš„ Agent"ï¼‰
4. ç‚¹å‡»**åˆ›å»º**
5. **ç«‹å³å¤åˆ¶å¯†é’¥** â€” å®ƒä¸ä¼šå†æ¬¡æ˜¾ç¤ºï¼

### æœ€ä½³å®è·µ

- **ä¸ºå¼€å‘/ç”Ÿäº§ä½¿ç”¨ä¸åŒå¯†é’¥** â€” æ›´å®¹æ˜“è°ƒè¯•å’Œè¿½è¸ªç”¨é‡
- **ä¸è¦å°†å¯†é’¥æäº¤åˆ° git** â€” ä½¿ç”¨ç¯å¢ƒå˜é‡ä»£æ›¿
- **å®šæœŸè½®æ¢å¯†é’¥** â€” å®‰å…¨ä¹ æƒ¯
- **ä½¿ç”¨æè¿°æ€§æ ‡ç­¾** â€” çŸ¥é“å“ªä¸ªåº”ç”¨ä½¿ç”¨å“ªä¸ªå¯†é’¥

### ä½¿ç”¨ç¤ºä¾‹

\`\`\`python
import os
from omem import Memory

# ä»ç¯å¢ƒå˜é‡åŠ è½½ï¼ˆæ¨èï¼‰
mem = Memory(api_key=os.environ["OMEM_API_KEY"])

# æˆ–ç›´æ¥ä½¿ç”¨ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
mem = Memory(api_key="qbk_your_key_here")
\`\`\``,
      },
    },
    {
      id: 'why-llm-required',
      heading: {
        en: 'Step 3: Why LLM Configuration is Required',
        zh: 'ç¬¬ä¸‰æ­¥ï¼šä¸ºä»€ä¹ˆéœ€è¦é…ç½® LLM',
      },
      content: {
        en: `Omni Memory uses LLMs to process your conversations and extract structured knowledge:

- **Entities** â€” People, places, organizations
- **Events** â€” Meetings, trips, deadlines
- **Relationships** â€” Connections between entities
- **Temporal Info** â€” Dates, times, durations

**Without an LLM configured, you'll see this error:**

\`\`\`
OmemValidationError: http_400: Missing required data for core ingest
{"missing": ["llm_api_key", "llm_provider", "llm_model"]}
\`\`\`

### BYOK (Bring Your Own Key)

We use a **BYOK model** â€” you provide your own LLM API key. This means:

- âœ… **You control costs** â€” Pay your LLM provider directly
- âœ… **You choose the model** â€” Use GPT-4, DeepSeek, Qwen, etc.
- âœ… **No vendor lock-in** â€” Switch providers anytime
- âœ… **Data privacy** â€” Your LLM key, your terms`,
        zh: `Omni Memory ä½¿ç”¨ LLM å¤„ç†æ‚¨çš„å¯¹è¯å¹¶æå–ç»“æ„åŒ–çŸ¥è¯†ï¼š

- **å®ä½“** â€” äººç‰©ã€åœ°ç‚¹ã€ç»„ç»‡
- **äº‹ä»¶** â€” ä¼šè®®ã€æ—…è¡Œã€æˆªæ­¢æ—¥æœŸ
- **å…³ç³»** â€” å®ä½“ä¹‹é—´çš„è¿æ¥
- **æ—¶é—´ä¿¡æ¯** â€” æ—¥æœŸã€æ—¶é—´ã€æŒç»­æ—¶é—´

**å¦‚æœæ²¡æœ‰é…ç½® LLMï¼Œæ‚¨ä¼šçœ‹åˆ°æ­¤é”™è¯¯ï¼š**

\`\`\`
OmemValidationError: http_400: Missing required data for core ingest
{"missing": ["llm_api_key", "llm_provider", "llm_model"]}
\`\`\`

### BYOKï¼ˆè‡ªå¸¦å¯†é’¥ï¼‰

æˆ‘ä»¬ä½¿ç”¨ **BYOK æ¨¡å¼** â€” æ‚¨æä¾›è‡ªå·±çš„ LLM API å¯†é’¥ã€‚è¿™æ„å‘³ç€ï¼š

- âœ… **æ‚¨æ§åˆ¶æˆæœ¬** â€” ç›´æ¥å‘ LLM æä¾›å•†ä»˜è´¹
- âœ… **æ‚¨é€‰æ‹©æ¨¡å‹** â€” ä½¿ç”¨ GPT-4ã€DeepSeekã€é€šä¹‰åƒé—®ç­‰
- âœ… **æ— ä¾›åº”å•†é”å®š** â€” éšæ—¶åˆ‡æ¢æä¾›å•†
- âœ… **æ•°æ®éšç§** â€” æ‚¨çš„ LLM å¯†é’¥ï¼Œæ‚¨çš„æ¡æ¬¾`,
      },
    },
    {
      id: 'configure-llm',
      heading: {
        en: 'Step 4: Configure Your LLM Provider',
        zh: 'ç¬¬å››æ­¥ï¼šé…ç½® LLM æä¾›å•†',
      },
      content: {
        en: `### Supported Providers

| Provider | Models | Get API Key |
|----------|--------|-------------|
| **OpenAI** | gpt-4o, gpt-4o-mini, gpt-4-turbo | [platform.openai.com](https://platform.openai.com/api-keys) |
| **DeepSeek** | deepseek-chat, deepseek-coder | [platform.deepseek.com](https://platform.deepseek.com/) |
| **Qwen (é€šä¹‰åƒé—®)** | qwen-turbo, qwen-plus, qwen-max | [dashscope.console.aliyun.com](https://dashscope.console.aliyun.com/) |
| **GLM (æ™ºè°±)** | glm-4, glm-4-flash | [open.bigmodel.cn](https://open.bigmodel.cn/) |
| **Gemini** | gemini-pro, gemini-1.5-pro | [aistudio.google.com](https://aistudio.google.com/apikey) |
| **Moonshot (æœˆä¹‹æš—é¢)** | moonshot-v1-8k, moonshot-v1-32k | [platform.moonshot.cn](https://platform.moonshot.cn/) |
| **OpenRouter** | Various models | [openrouter.ai](https://openrouter.ai/keys) |

### How to Add Your LLM Key

1. Go to **Dashboard â†’ Memory Policy** (è®°å¿†ç­–ç•¥)
2. Scroll to **"Add LLM Key"** (æ·»åŠ  LLM å¯†é’¥) section
3. Fill in the form:
   - **Label** (å¤‡æ³¨) â€” A name to identify this key (e.g., "My OpenAI Key")
   - **LLM Key** (LLM å¯†é’¥) â€” Your API key from the provider (e.g., \`sk-proj-xxx...\`)
   - **Provider** (å¹³å°) â€” Select from dropdown (e.g., OpenAI)
   - **Model** (æ¨¡å‹åç§°) â€” Auto-loads after selecting provider (e.g., gpt-4o-mini)
4. Click **Add** (æ·»åŠ )
5. Set **Binding Scope** (ç»‘å®šèŒƒå›´):
   - **All API Keys** (æ‰€æœ‰ API å¯†é’¥) â€” This LLM key is used for all your Omni Memory API keys (recommended for most users)
   - **Specific API Key** â€” Only used when that specific API key makes requests

### Recommended Setup

For most users, we recommend:

- **Provider:** OpenAI or DeepSeek (best balance of quality/cost)
- **Model:** gpt-4o-mini or deepseek-chat (cost-effective, good extraction)
- **Binding:** All API Keys (simplest setup)`,
        zh: `### æ”¯æŒçš„æä¾›å•†

| æä¾›å•† | æ¨¡å‹ | è·å– API å¯†é’¥ |
|--------|------|---------------|
| **OpenAI** | gpt-4o, gpt-4o-mini, gpt-4-turbo | [platform.openai.com](https://platform.openai.com/api-keys) |
| **DeepSeek** | deepseek-chat, deepseek-coder | [platform.deepseek.com](https://platform.deepseek.com/) |
| **é€šä¹‰åƒé—®** | qwen-turbo, qwen-plus, qwen-max | [dashscope.console.aliyun.com](https://dashscope.console.aliyun.com/) |
| **æ™ºè°± GLM** | glm-4, glm-4-flash | [open.bigmodel.cn](https://open.bigmodel.cn/) |
| **Gemini** | gemini-pro, gemini-1.5-pro | [aistudio.google.com](https://aistudio.google.com/apikey) |
| **æœˆä¹‹æš—é¢** | moonshot-v1-8k, moonshot-v1-32k | [platform.moonshot.cn](https://platform.moonshot.cn/) |
| **OpenRouter** | å¤šç§æ¨¡å‹ | [openrouter.ai](https://openrouter.ai/keys) |

### å¦‚ä½•æ·»åŠ  LLM å¯†é’¥

1. è¿›å…¥**æ§åˆ¶å° â†’ è®°å¿†ç­–ç•¥**
2. æ»šåŠ¨åˆ°**"æ·»åŠ  LLM å¯†é’¥"**éƒ¨åˆ†
3. å¡«å†™è¡¨å•ï¼š
   - **å¤‡æ³¨** â€” ç”¨äºè¯†åˆ«æ­¤å¯†é’¥çš„åç§°ï¼ˆå¦‚"æˆ‘çš„ OpenAI å¯†é’¥"ï¼‰
   - **LLM å¯†é’¥** â€” æ¥è‡ªæä¾›å•†çš„ API å¯†é’¥ï¼ˆå¦‚ \`sk-proj-xxx...\`ï¼‰
   - **å¹³å°** â€” ä»ä¸‹æ‹‰èœå•é€‰æ‹©ï¼ˆå¦‚ OpenAIï¼‰
   - **æ¨¡å‹åç§°** â€” é€‰æ‹©å¹³å°åè‡ªåŠ¨åŠ è½½ï¼ˆå¦‚ gpt-4o-miniï¼‰
4. ç‚¹å‡»**æ·»åŠ **
5. è®¾ç½®**ç»‘å®šèŒƒå›´**ï¼š
   - **æ‰€æœ‰ API å¯†é’¥** â€” æ­¤ LLM å¯†é’¥ç”¨äºæ‚¨æ‰€æœ‰çš„ Omni Memory API å¯†é’¥ï¼ˆå¤§å¤šæ•°ç”¨æˆ·æ¨èï¼‰
   - **ç‰¹å®š API å¯†é’¥** â€” ä»…åœ¨è¯¥ç‰¹å®š API å¯†é’¥å‘å‡ºè¯·æ±‚æ—¶ä½¿ç”¨

### æ¨èè®¾ç½®

å¯¹äºå¤§å¤šæ•°ç”¨æˆ·ï¼Œæˆ‘ä»¬æ¨èï¼š

- **å¹³å°ï¼š** OpenAI æˆ– DeepSeekï¼ˆè´¨é‡/æˆæœ¬æœ€ä½³å¹³è¡¡ï¼‰
- **æ¨¡å‹ï¼š** gpt-4o-mini æˆ– deepseek-chatï¼ˆæ€§ä»·æ¯”é«˜ï¼Œæå–æ•ˆæœå¥½ï¼‰
- **ç»‘å®šï¼š** æ‰€æœ‰ API å¯†é’¥ï¼ˆæœ€ç®€å•çš„è®¾ç½®ï¼‰`,
      },
    },
    {
      id: 'verify-setup',
      heading: {
        en: 'Step 5: Verify Your Setup',
        zh: 'ç¬¬äº”æ­¥ï¼šéªŒè¯è®¾ç½®',
      },
      content: {
        en: `Run this quick test to verify everything is configured correctly:

\`\`\`python
from omem import Memory

mem = Memory(api_key="qbk_your_key_here")

# Test: Save a conversation
mem.add("test-conv-001", [
    {"role": "user", "content": "Meeting with Alice tomorrow at 3pm"},
    {"role": "assistant", "content": "Got it, I'll remember that."},
])

print("âœ… Setup successful! Memory saved.")

# Wait ~10 seconds for processing, then search
import time
time.sleep(10)

result = mem.search("meeting with Alice")
if result:
    print(f"âœ… Search works! Found {len(result.items)} results")
    print(result.to_prompt())
else:
    print("â³ No results yet - try again in a few seconds")
\`\`\`

### Expected Output

\`\`\`
âœ… Setup successful! Memory saved.
âœ… Search works! Found 1 results
[Memory]
- Meeting with Alice tomorrow at 3pm
\`\`\`

### Troubleshooting

| Error | Cause | Solution |
|-------|-------|----------|
| \`Missing required data for core ingest\` | No LLM configured | Add LLM key in Memory Policy |
| \`OmemAuthError: http_401\` | Invalid API key | Check your \`qbk_\` key is correct |
| \`OmemForbiddenError: http_403\` | Key disabled or expired | Create a new API key |
| \`OmemRateLimitError: http_429\` | Too many requests | Wait and retry, or upgrade plan |
| Search returns empty | Processing not complete | Wait 10-30 seconds after \`add()\` |`,
        zh: `è¿è¡Œæ­¤å¿«é€Ÿæµ‹è¯•ä»¥éªŒè¯ä¸€åˆ‡é…ç½®æ­£ç¡®ï¼š

\`\`\`python
from omem import Memory

mem = Memory(api_key="qbk_your_key_here")

# æµ‹è¯•ï¼šä¿å­˜å¯¹è¯
mem.add("test-conv-001", [
    {"role": "user", "content": "æ˜å¤©ä¸‹åˆ3ç‚¹å’Œ Alice å¼€ä¼š"},
    {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘è®°ä½äº†ã€‚"},
])

print("âœ… è®¾ç½®æˆåŠŸï¼è®°å¿†å·²ä¿å­˜ã€‚")

# ç­‰å¾…çº¦10ç§’å¤„ç†ï¼Œç„¶åæœç´¢
import time
time.sleep(10)

result = mem.search("å’Œ Alice å¼€ä¼š")
if result:
    print(f"âœ… æœç´¢æœ‰æ•ˆï¼æ‰¾åˆ° {len(result.items)} æ¡ç»“æœ")
    print(result.to_prompt())
else:
    print("â³ æš‚æ— ç»“æœ - å‡ ç§’åé‡è¯•")
\`\`\`

### é¢„æœŸè¾“å‡º

\`\`\`
âœ… è®¾ç½®æˆåŠŸï¼è®°å¿†å·²ä¿å­˜ã€‚
âœ… æœç´¢æœ‰æ•ˆï¼æ‰¾åˆ° 1 æ¡ç»“æœ
[Memory]
- æ˜å¤©ä¸‹åˆ3ç‚¹å’Œ Alice å¼€ä¼š
\`\`\`

### æ•…éšœæ’é™¤

| é”™è¯¯ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| \`Missing required data for core ingest\` | æœªé…ç½® LLM | åœ¨è®°å¿†ç­–ç•¥ä¸­æ·»åŠ  LLM å¯†é’¥ |
| \`OmemAuthError: http_401\` | API å¯†é’¥æ— æ•ˆ | æ£€æŸ¥ \`qbk_\` å¯†é’¥æ˜¯å¦æ­£ç¡® |
| \`OmemForbiddenError: http_403\` | å¯†é’¥å·²ç¦ç”¨æˆ–è¿‡æœŸ | åˆ›å»ºæ–°çš„ API å¯†é’¥ |
| \`OmemRateLimitError: http_429\` | è¯·æ±‚è¿‡å¤š | ç­‰å¾…åé‡è¯•ï¼Œæˆ–å‡çº§è®¡åˆ’ |
| æœç´¢è¿”å›ç©º | å¤„ç†æœªå®Œæˆ | åœ¨ \`add()\` åç­‰å¾… 10-30 ç§’ |`,
      },
    },
    {
      id: 'advanced-binding',
      heading: {
        en: 'Advanced: Multiple LLM Keys',
        zh: 'é«˜çº§ï¼šå¤šä¸ª LLM å¯†é’¥',
      },
      content: {
        en: `You can configure multiple LLM keys for different use cases. For example:

**Use Case 1: Different Models for Dev vs Prod**
- Dev API key â†’ Use cheaper model (gpt-4o-mini)
- Prod API key â†’ Use better model (gpt-4o)

**Use Case 2: Cost Optimization**
- High-volume agent â†’ Use DeepSeek (cheap)
- Premium users â†’ Use OpenAI (best quality)

### How to Set Up

1. Add multiple LLM keys in Memory Policy
2. For each LLM key, change **Binding Scope** from "All API Keys" to a specific API key
3. Requests using that API key will use the bound LLM`,
        zh: `æ‚¨å¯ä»¥ä¸ºä¸åŒç”¨ä¾‹é…ç½®å¤šä¸ª LLM å¯†é’¥ã€‚ä¾‹å¦‚ï¼š

**ç”¨ä¾‹ 1ï¼šå¼€å‘ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨ä¸åŒæ¨¡å‹**
- å¼€å‘ API å¯†é’¥ â†’ ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆgpt-4o-miniï¼‰
- ç”Ÿäº§ API å¯†é’¥ â†’ ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹ï¼ˆgpt-4oï¼‰

**ç”¨ä¾‹ 2ï¼šæˆæœ¬ä¼˜åŒ–**
- é«˜æµé‡ Agent â†’ ä½¿ç”¨ DeepSeekï¼ˆä¾¿å®œï¼‰
- é«˜çº§ç”¨æˆ· â†’ ä½¿ç”¨ OpenAIï¼ˆæœ€ä½³è´¨é‡ï¼‰

### å¦‚ä½•è®¾ç½®

1. åœ¨è®°å¿†ç­–ç•¥ä¸­æ·»åŠ å¤šä¸ª LLM å¯†é’¥
2. å¯¹äºæ¯ä¸ª LLM å¯†é’¥ï¼Œå°†**ç»‘å®šèŒƒå›´**ä»"æ‰€æœ‰ API å¯†é’¥"æ›´æ”¹ä¸ºç‰¹å®š API å¯†é’¥
3. ä½¿ç”¨è¯¥ API å¯†é’¥çš„è¯·æ±‚å°†ä½¿ç”¨ç»‘å®šçš„ LLM`,
      },
    },
    {
      id: 'next-steps',
      heading: {
        en: 'Next Steps',
        zh: 'ä¸‹ä¸€æ­¥',
      },
      content: {
        en: `You're all set! Here's what to do next:

- ğŸ“š [Python SDK Reference](/docs/sdk/python) â€” Full API documentation
- ğŸ¤– [Agent Integration](/docs/guides/agent) â€” Add memory to your LLM agent
- ğŸ‘¥ [Multi-Speaker Conversations](/docs/guides/multi-speaker) â€” Handle group chats
- â“ [Error Codes](/docs/reference/errors) â€” Troubleshoot issues`,
        zh: `è®¾ç½®å®Œæˆï¼æ¥ä¸‹æ¥å¯ä»¥ï¼š

- ğŸ“š [Python SDK å‚è€ƒ](/docs/sdk/python) â€” å®Œæ•´ API æ–‡æ¡£
- ğŸ¤– [Agent é›†æˆ](/docs/guides/agent) â€” ä¸ºæ‚¨çš„ LLM Agent æ·»åŠ è®°å¿†
- ğŸ‘¥ [å¤šè¯´è¯äººå¯¹è¯](/docs/guides/multi-speaker) â€” å¤„ç†ç¾¤èŠ
- â“ [é”™è¯¯ç ](/docs/reference/errors) â€” é—®é¢˜æ’æŸ¥`,
      },
    },
  ],
};
